{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8TI06LT8ILsg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers import LeakyReLU, ReLU\n",
    "from keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "executionInfo": {
     "elapsed": 1855,
     "status": "ok",
     "timestamp": 1669761331659,
     "user": {
      "displayName": "Hassan",
      "userId": "10703162273548565377"
     },
     "user_tz": 300
    },
    "id": "Di3go67WIfzs",
    "outputId": "09fd1586-71df-47f8-ac8b-fcf884768142"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.4482</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.15747</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.152920</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.096603</td>\n",
       "      <td>0.52135</td>\n",
       "      <td>0.38205</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.94590</td>\n",
       "      <td>0.219960</td>\n",
       "      <td>-0.69045</td>\n",
       "      <td>0.24044</td>\n",
       "      <td>-0.258640</td>\n",
       "      <td>1.33870</td>\n",
       "      <td>0.114820</td>\n",
       "      <td>-0.43046</td>\n",
       "      <td>0.82309</td>\n",
       "      <td>1.54350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.3019</td>\n",
       "      <td>0.188490</td>\n",
       "      <td>0.55319</td>\n",
       "      <td>0.258290</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.039008</td>\n",
       "      <td>0.43211</td>\n",
       "      <td>0.52716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.22680</td>\n",
       "      <td>-0.428570</td>\n",
       "      <td>0.74992</td>\n",
       "      <td>-0.11192</td>\n",
       "      <td>1.583000</td>\n",
       "      <td>0.88565</td>\n",
       "      <td>-0.053227</td>\n",
       "      <td>0.67796</td>\n",
       "      <td>-1.72010</td>\n",
       "      <td>-0.55051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2894</td>\n",
       "      <td>0.052169</td>\n",
       "      <td>0.43852</td>\n",
       "      <td>0.494030</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.39484</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15790</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>0.73593</td>\n",
       "      <td>1.35600</td>\n",
       "      <td>0.057821</td>\n",
       "      <td>-1.44140</td>\n",
       "      <td>1.581800</td>\n",
       "      <td>1.25420</td>\n",
       "      <td>1.02540</td>\n",
       "      <td>-1.01890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.6207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.109340</td>\n",
       "      <td>0.49344</td>\n",
       "      <td>0.39300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.69767</td>\n",
       "      <td>1.577800</td>\n",
       "      <td>0.54899</td>\n",
       "      <td>-0.78042</td>\n",
       "      <td>1.136700</td>\n",
       "      <td>-0.84240</td>\n",
       "      <td>0.993120</td>\n",
       "      <td>-0.44576</td>\n",
       "      <td>-0.78778</td>\n",
       "      <td>-1.49090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.8439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>0.54986</td>\n",
       "      <td>0.17016</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.30520</td>\n",
       "      <td>0.67046</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.49170</td>\n",
       "      <td>-0.688640</td>\n",
       "      <td>-0.69924</td>\n",
       "      <td>0.36074</td>\n",
       "      <td>-0.685860</td>\n",
       "      <td>-0.76161</td>\n",
       "      <td>-0.354560</td>\n",
       "      <td>0.83093</td>\n",
       "      <td>-0.27100</td>\n",
       "      <td>0.38861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1        2         3         4        5        6         7    \\\n",
       "0  3.4482  0.001314  0.15747  0.688300  0.152920  0.00000  0.00000  0.096603   \n",
       "1  3.3019  0.188490  0.55319  0.258290  0.000031  0.00000  0.00000  0.039008   \n",
       "2  2.2894  0.052169  0.43852  0.494030  0.015282  0.00000  0.00000  0.000000   \n",
       "3  2.6207  0.000000  0.00000  0.004213  0.109340  0.49344  0.39300  0.000000   \n",
       "4  2.8439  0.000000  0.00000  0.019504  0.260470  0.54986  0.17016  0.010568   \n",
       "\n",
       "       8        9    ...      502       503      504      505       506  \\\n",
       "0  0.52135  0.38205  ... -2.94590  0.219960 -0.69045  0.24044 -0.258640   \n",
       "1  0.43211  0.52716  ... -0.22680 -0.428570  0.74992 -0.11192  1.583000   \n",
       "2  0.00000  0.39484  ...  1.15790  0.010118  0.73593  1.35600  0.057821   \n",
       "3  0.00000  0.57854  ... -0.69767  1.577800  0.54899 -0.78042  1.136700   \n",
       "4  0.30520  0.67046  ... -1.49170 -0.688640 -0.69924  0.36074 -0.685860   \n",
       "\n",
       "       507       508      509      510      511  \n",
       "0  1.33870  0.114820 -0.43046  0.82309  1.54350  \n",
       "1  0.88565 -0.053227  0.67796 -1.72010 -0.55051  \n",
       "2 -1.44140  1.581800  1.25420  1.02540 -1.01890  \n",
       "3 -0.84240  0.993120 -0.44576 -0.78778 -1.49090  \n",
       "4 -0.76161 -0.354560  0.83093 -0.27100  0.38861  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/AirI.csv', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "80HMeBUpI0Lt"
   },
   "outputs": [],
   "source": [
    "Xf = data.values\n",
    "x = Xf[:, 1:]\n",
    "y = Xf[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdMjB2kwLKeO"
   },
   "source": [
    "1. Implement a neural network model for regression in the case of the air quality dataset (AirI.csv). As before, the dependent variable y is the first column, and the input variables are the rest of the columns. Consider measuring the external validity from a 5-fold cross-validation; in this exercise, you would have to implement your design of the neural network that includes experimentation with the number of layers, neurons per layer, choice of activation functions, kernel regularizations, etc. As guidance, you would know that your model is doing reasonably well if the external validity (average MSE on the test sets) is less than 0.29.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QJIFNMTjI2st"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "scale = SS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207773,
     "status": "ok",
     "timestamp": 1669764240463,
     "user": {
      "displayName": "Hassan",
      "userId": "10703162273548565377"
     },
     "user_tz": 300
    },
    "id": "t6mSef4JK0rU",
    "outputId": "8a595f07-963f-48ea-d590-f36e01862d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n",
      "0.21860227150166714\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "0.16850986371326024\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "0.28948136880120123\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "0.4855015505241592\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8a356bb1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "0.1761438559863762\n",
      "The External Validation of the Neural Network model is : 0.2676477821053328\n"
     ]
    }
   ],
   "source": [
    "PE = []\n",
    "\n",
    "for idxtrain, idxtest in kf.split(x):\n",
    "  # subset and scale data\n",
    "    xtrain = scale.fit_transform(x[idxtrain])\n",
    "    xtest = scale.transform(x[idxtest])\n",
    "    ytrain = y[idxtrain]\n",
    "    ytest = y[idxtest]\n",
    "\n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(x.shape[1], activation=LeakyReLU(0.1), kernel_regularizer=l2(0.001), use_bias=True,input_dim=x.shape[1]))\n",
    "    model.add(Dense(x.shape[1], activation=LeakyReLU(0.01), kernel_regularizer=l2(0.001), use_bias=True))\n",
    "    # output layer with 1 neuron b/c we're solve a regression problem\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mse',optimizer=opt)\n",
    "    model.fit(xtrain,ytrain,epochs=1000,verbose=0, batch_size=np.floor(xtrain.shape[0]/16).astype(int))\n",
    "    mse_test = mse(ytest, model.predict(xtest))\n",
    "    print(mse_test)\n",
    "    PE.append(mse_test)\n",
    "print('The External Validation of the Neural Network model is : ' + str(np.mean(PE)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpBCl2qAuIh5"
   },
   "source": [
    "---\n",
    "2. Based on the class examples, design and implement a convolutional neural network model for classification in the case of the MNIST dataset and measure the validity in the test sets. The average accuracy on the test sets is expected to be at least 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gVnazPLOORDA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator # to create realistic geometrical deformations of the images\n",
    "from tensorflow.keras.utils import to_categorical # this does the same as OneHotEncoder\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import os\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EFz2eMDm13WF"
   },
   "outputs": [],
   "source": [
    "(trainX, trainy), (testX, testy) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t_KOJI5YwH7L"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    (trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def prep_pixels(train, test):\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    return train_norm, test_norm\n",
    "\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    opt = Adam(learning_rate=0.002)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "    scores, histories = list(), list()\n",
    "    kfold = StratifiedKFold(n_folds, shuffle=True, random_state=1234)\n",
    "    for train_ix, test_ix in kfold.split(dataX,trainy):\n",
    "        model = define_model()\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        history = model.fit(trainX, trainY, epochs=25, batch_size=150, validation_data=(testX, testY), verbose=0)\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "    return scores, histories, model\n",
    "\n",
    "def summarize_diagnostics(histories):\n",
    "    for i in range(len(histories)):\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "        plt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "        plt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
    "        plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "\n",
    "def summarize_performance(scores):\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (np.mean(scores)*100, np.std(scores)*100, len(scores)))\n",
    "    plt.boxplot(scores)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_everything():\n",
    "    vals= []\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    scores, histories, model = evaluate_model(trainX, trainY)\n",
    "    vals.append(scores)\n",
    "    summarize_diagnostics(histories)\n",
    "    summarize_performance(scores)\n",
    "    print('The overall accuracy is :'+str(np.mean(vals)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 303690,
     "status": "ok",
     "timestamp": 1669768720487,
     "user": {
      "displayName": "Hassan",
      "userId": "10703162273548565377"
     },
     "user_tz": 300
    },
    "id": "47iOOfUDxNlI",
    "outputId": "1268b6c9-1ae9-450c-a847-3df621fc2646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 99.133\n"
     ]
    }
   ],
   "source": [
    "model = run_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ch2BRRtxOH8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7OJRlgS-xOz6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LMdS9VE4ogP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPWKSC8OX4gmumgbMksBqc3",
   "mount_file_id": "1zcUsthmeExNNvZBN-xyzvWl8OVmTtoU0",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
